/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 * <p>
 * http://www.apache.org/licenses/LICENSE-2.0
 * <p>
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

syntax = "proto3";

package ballista.protobuf;

option java_multiple_files = true;
option java_package = "org.apache.arrow.ballista.protobuf";
option java_outer_classname = "BallistaProto";

import "datafusion.proto";

///////////////////////////////////////////////////////////////////////////////////////////////////
// Ballista Physical Plan
///////////////////////////////////////////////////////////////////////////////////////////////////
message BallistaPhysicalPlanNode {
  oneof PhysicalPlanType {
    ShuffleWriterExecNode shuffle_writer = 1;
    ShuffleReaderExecNode shuffle_reader = 2;
    UnresolvedShuffleExecNode unresolved_shuffle = 3;
  }
}

message ShuffleWriterExecNode {
  //TODO it seems redundant to provide job and stage id here since we also have them
  // in the TaskDefinition that wraps this plan
  string job_id = 1;
  uint32 stage_id = 2;
  datafusion.PhysicalPlanNode input = 3;
  datafusion.PhysicalHashRepartition output_partitioning = 4;
}

message UnresolvedShuffleExecNode {
  uint32 stage_id = 1;
  datafusion.Schema schema = 2;
  uint32 output_partition_count = 4;
}

message ShuffleReaderExecNode {
  repeated ShuffleReaderPartition partition = 1;
  datafusion.Schema schema = 2;
  // The stage to read from
  uint32 stage_id = 3;
}

message ShuffleReaderPartition {
  // each partition of a shuffle read can read data from multiple locations
  repeated PartitionLocation location = 1;
}

///////////////////////////////////////////////////////////////////////////////////////////////////
// Ballista Scheduling
///////////////////////////////////////////////////////////////////////////////////////////////////
message ExecutionGraph {
  string job_id = 1;
  string session_id = 2;
  JobStatus status = 3;
  repeated ExecutionGraphStage stages = 4;
  uint64 output_partitions = 5;
  repeated PartitionLocation output_locations = 6;
  string scheduler_id = 7;
  uint32 task_id_gen = 8;
  uint64 start_time = 11;
  uint64 end_time = 12;
  uint64 queued_at = 13;
}

message ExecutionGraphStage {
  oneof StageType {
    UnResolvedStage unresolved_stage = 1;
    ResolvedStage resolved_stage = 2;
    SuccessfulStage successful_stage = 3;
  }
}

message UnResolvedStage {
  uint32 stage_id = 1;
  repeated uint32 output_links = 3;
  repeated  GraphStageInput inputs = 4;
  bytes plan = 5;
}

message ResolvedStage {
  uint32 stage_id = 1;
  uint32 partitions = 2;
  repeated uint32 output_links = 4;
  repeated  GraphStageInput inputs = 5;
  bytes plan = 6;
}

message SuccessfulStage {
  uint32 stage_id = 1;
  uint32 partitions = 2;
  repeated uint32 output_links = 4;
  repeated  GraphStageInput inputs = 5;
  bytes plan = 6;
  repeated TaskInfo task_infos = 7;
  repeated OperatorMetricsSet stage_metrics = 8;
}

message TaskInfo {
  uint32 task_id = 1;
  uint32 partition_id = 2;
  // Scheduler schedule time
  uint64 scheduled_time = 3;
  // Scheduler launch time
  uint64 launch_time = 4;
  // The time the Executor start to run the task
  uint64 start_exec_time = 5;
  // The time the Executor finish the task
  uint64 end_exec_time = 6;
  // Scheduler side finish time
  uint64 finish_time = 7;
  oneof status {
    RunningTask running = 8;
    FailedTask failed = 9;
    SuccessfulTask successful = 10;
  }
}

message GraphStageInput {
  uint32 stage_id = 1;
  repeated TaskInputPartitions partition_locations = 2;
  bool complete = 3;
}

message TaskInputPartitions {
  uint32 partition = 1;
  repeated PartitionLocation partition_location = 2;
}

message KeyValuePair {
  string key = 1;
  string value = 2;
}

message Action {

  oneof ActionType {
    // Fetch a partition from an executor
    FetchPartition fetch_partition = 3;
  }

  // configuration settings
  repeated KeyValuePair settings = 100;
}

message FetchPartition {
  string job_id = 1;
  uint32 stage_id = 2;
  uint32 partition_id = 3;
  string path = 4;
  string host = 5;
  uint32 port = 6;
}

message PartitionLocation {
  // partition_id of the shuffle, a composition of(job_id + map_stage_id + partition_id).
  PartitionId partition_id = 2;
  ExecutorMetadata executor_meta = 3;
  PartitionStats partition_stats = 4;
  string path = 5;
}

// Unique identifier for a materialized partition of data
message PartitionId {
  string job_id = 1;
  uint32 stage_id = 2;
  uint32 partition_id = 4;
}

message TaskId {
  uint32 task_id = 1;
  uint32 partition_id = 3;
}

message PartitionStats {
  int64 num_rows = 1;
  int64 num_batches = 2;
  int64 num_bytes = 3;
  repeated ColumnStats column_stats = 4;
}

message ColumnStats {
  datafusion.ScalarValue min_value = 1;
  datafusion.ScalarValue max_value = 2;
  uint32 null_count = 3;
  uint32 distinct_count = 4;
}

message OperatorMetricsSet {
  repeated OperatorMetric metrics = 1;
}


message NamedCount {
  string name = 1;
  uint64 value = 2;
}

message NamedGauge {
  string name = 1;
  uint64 value = 2;
}

message NamedTime {
  string name = 1;
  uint64 value = 2;
}

message OperatorMetric {
  oneof metric {
    uint64 output_rows = 1;
    uint64 elapse_time = 2;
    uint64 spill_count = 3;
    uint64 spilled_bytes = 4;
    uint64 current_memory_usage = 5;
    NamedCount count = 6;
    NamedGauge gauge = 7;
    NamedTime time = 8;
    int64 start_timestamp = 9;
    int64 end_timestamp = 10;
  }
}

// Used by scheduler
message ExecutorMetadata {
  string id = 1;
  string host = 2;
  uint32 port = 3;
  uint32 grpc_port = 4;
  ExecutorSpecification specification = 5;
}


// Used by grpc
message ExecutorRegistration {
  string id = 1;
  uint32 port = 3;
  uint32 grpc_port = 4;
  ExecutorSpecification specification = 5;
}

message ExecutorHeartbeat {
  string executor_id = 1;
  // Unix epoch-based timestamp in seconds
  uint64 timestamp = 2;
  ExecutorStatus status = 4;
}

message ExecutorStatus {
  oneof status {
    string active = 1;
    string dead = 2;
    string unknown = 3;
    string terminating = 4;
  }
}

message ExecutorSpecification {
  repeated ExecutorResource resources = 1;
}

message ExecutorResource {
  // TODO add more resources
  oneof resource {
    uint32 task_slots = 1;
  }
}

message AvailableTaskSlots {
  string executor_id = 1;
  uint32 slots = 2;
}

message ExecutorTaskSlots {
  repeated AvailableTaskSlots task_slots = 1;
}

message RunningTask {
  string executor_id = 1;
}

message FailedTask {
  string error = 1;
}

message SuccessfulTask {
  string executor_id = 1;
  // TODO tasks are currently always shuffle writes but this will not always be the case
  // so we might want to think about some refactoring of the task definitions
  repeated ShuffleWritePartition partitions = 2;
}

message ShuffleWritePartition {
  uint64 partition_id = 1;
  string path = 2;
  uint64 num_batches = 3;
  uint64 num_rows = 4;
  uint64 num_bytes = 5;
}

message TaskStatus {
  uint32 task_id = 1;
  string job_id = 2;
  uint32 stage_id = 3;
  uint32 partition_id = 5;
  uint64 launch_time = 6;
  uint64 start_exec_time = 7;
  uint64 end_exec_time = 8;
  oneof status {
    RunningTask running = 9;
    FailedTask failed = 10;
    SuccessfulTask successful = 11;
  }
  repeated OperatorMetricsSet metrics = 12;
}

// A set of tasks in the same stage
message MultiTaskDefinition {
  repeated TaskId task_ids = 1;
  string job_id = 2;
  uint32 stage_id = 3;
  bytes plan = 5;
  string session_id = 7;
  uint64 launch_time = 8;
  repeated KeyValuePair props = 9;
}

message SessionSettings {
  repeated KeyValuePair configs = 1;
}

message HeartBeatParams {
  string executor_id = 1;
  ExecutorStatus status = 2;
  ExecutorRegistration metadata = 3;
}

message HeartBeatResult {
}

message UpdateTaskStatusParams {
  string executor_id = 1;
  // All tasks must be reported until they reach the failed or completed state
  repeated TaskStatus task_status = 2;
}

message UpdateTaskStatusResult {
  bool success = 1;
}

message SuccessfulJob {
  repeated PartitionLocation partition_location = 1;
  uint64 queued_at = 2;
  uint64 started_at = 3;
  uint64 ended_at = 4;
}

message QueuedJob {
  uint64 queued_at = 1;
}

// TODO: add progress report
message RunningJob {
  uint64 queued_at = 1;
  uint64 started_at = 2;
  string scheduler = 3;
}

message FailedJob {
  string error = 1;
  uint64 queued_at = 2;
  uint64 started_at = 3;
  uint64 ended_at = 4;
}

message JobStatus {
  string job_id = 5;

  oneof status {
    QueuedJob queued = 1;
    RunningJob running = 2;
    FailedJob failed = 3;
    SuccessfulJob successful = 4;
  }
}

message LaunchMultiTaskParams {
  // Allow to launch a task set to an executor at once
  repeated MultiTaskDefinition multi_tasks = 1;
  string scheduler_id = 2;
}

message LaunchMultiTaskResult {
  bool success = 1;
  // TODO when part of the task set are scheduled successfully
}

message CancelTasksParams {
  repeated RunningTaskInfo task_infos = 1;
}

message CancelTasksResult {
  bool cancelled = 1;
}

message RemoveJobDataParams {
  string job_id = 1;
}

message RemoveJobDataResult {
}

message RunningTaskInfo {
  uint32 task_id = 1;
  string job_id = 2;
  uint32 stage_id = 3;
  uint32 partition_id = 4;;
}

service SchedulerGrpc {
  rpc HeartBeatFromExecutor (HeartBeatParams) returns (HeartBeatResult) {}

  rpc UpdateTaskStatus (UpdateTaskStatusParams) returns (UpdateTaskStatusResult) {}
}

service ExecutorGrpc {
  rpc LaunchMultiTask (LaunchMultiTaskParams) returns (LaunchMultiTaskResult) {}

  rpc CancelTasks (CancelTasksParams) returns (CancelTasksResult) {}

  rpc RemoveJobData (RemoveJobDataParams) returns (RemoveJobDataResult) {}
}
